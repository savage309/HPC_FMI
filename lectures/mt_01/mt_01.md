![](./images/turing.png)

---

# Multithreading in practice

---

## Thread affinity

- pinning a thread to run on a specified core

---

# Multithread paradigms

- message passing
- shared state

---

## Message passing

- no common resources
  - no corrupted state
- all data for the task is passed to the thread
- the result is send back

Can be expensive if the data is really copied from one thread to another.

- Transfer only ownership over data

---

## Shared State

- Transactional memory
- Mutual exclusion

---

### Transactional memory

- Like ACID but without D
- like database transaction -> commit

Hardware and software implementations
- software is actually too slow to be used
- hardware is not popular

---

## Algorithms

---

### Deadlocks

---

 A deadlock situation can arise if **all** of the following conditions hold simultaneously in a system:
 
1.Mutual exclusion: at least one resource must be held in a non-shareable mode.[1] Only one process can use the resource at any given instant of time.

2.Hold and wait or resource holding: a process is currently holding at least one resource and requesting additional resources which are being held by other processes.

3.No preemption: a resource can be released only voluntarily by the process holding it.

4.Circular wait: a process must be waiting for a resource which is being held by another process, which in turn is waiting for the first process to release the resource. In general, there is a set of waiting processes, P = {P1, P2, ..., PN}, such that P1 is waiting for a resource held by P2, P2 is waiting for a resource held by P3 and so on until PN is waiting for a resource held by P1.


---

The [Dining Philosophers problem][p].

[p]: https://en.wikipedia.org/wiki/Dining_philosophers_problem

---

![Dining Philosophers problem](./images/Dining_philosophers.png)

---

#### Attempt 1

1. Pick the left fork
2. Pick the right fork
3. Eat for a while
4. Put the right fork down
5. Put the left fork down
6. Go to 1

---

#### Attempt 2

1. Pick the left fork
2. Pick the right fork or put the left fork down if you wait more than 5 minutes
   and goto 1
3. Eat for a while
4. Put the right fork down
5. Put the left fork down
6. Go to 1

---


#### Solution

Assign numbers to each forks and always pick the forks in order of increasing
numbers.

---

1. Philosopher A picks forks 1 and 2
2. Philosopher B waits for fork 2 and graps it as soon as A puts it down
3. Philosopher C picks forks 3 and 4
4. Philosopher D waits for fork 4 and graps it as soon as C puts it down
5. Philosopher E waits for fork 1 and graps it as soon as A puts it down

---

1. Philosopher A drops forks 2 and 1
2. Philosopher B graps 1 and waits for fork 3
3. Philosopher C drops forks 4 and 3
4. Philosopher D graps forks 4 and 5 
5. Philosopher E picks fork 1 and waits for fork 5 

---

1. Philosopher A waits for 1 and 2
2. Philosopher B graps 1 and 2
3. Philosopher C waits for 3 and 4
4. Philosopher D drops 4 and 5
5. Philosopher E picks fork 1 and 5

---

### !

Always lock your resources in global predefined order

---

Or use a single resource.

---

## User and system mode

---

User-mode locks:

- CriticalSection (becomes kernel after some spins)
- futex - Linux kernel primitive for user mode mutex ?!

---

User-mode threads:

- coroutines, fibers
- cooperative multitasking

---

# DIY mutex with atomic operations

---

```
	struct Mutex
	{
		void Lock() {
			bool isLocked = false
			while (locked) ; // Busy wait
			locked = true;
		}
		void Unlock() {
			locked = false;
		}

		std::atomic<bool> locked;
	};
```

---

## ???

---

- Not atomic

```
	while (locked) ; // Busy wait
	locked = true;
```

---

```
	struct Mutex
	{
		void Lock() {
			bool isLocked = false
			while (!locked.compare_exchange_strong(isLocked, true)) {
				isLocked = false;
			}
		}
		void Unlock() {
			locked = false;
		}

		std::atomic<bool> locked;
	};
```

---

## Atomic data structures

---

### Atomic stack

---

```
	 class Stack {
		std::atomic<Obj*> top_ptr;
		Obj* Pop() {
		  while(1) {
			Obj* ret_ptr = top_ptr;
			if (!ret_ptr) return std::nullptr;
			Obj* next_ptr = ret_ptr->next;
			if (top_ptr.compare_exchange_weak(ret_ptr, next_ptr)) {
			  return ret_ptr;
			}
			// The stack has changed, start over.
		  }
		}
		//
		// Pushes the object specified by obj_ptr to stack.
		//
		void Push(Obj* obj_ptr) {
		  while(1) {
			Obj* next_ptr = top_ptr;
			obj_ptr->next = next_ptr;
			if (top_ptr.compare_exchange_weak(next_ptr, obj_ptr)) {
			  return;
			}
			// The stack has changed, start over.
		  }
		}
	  };
```

---

### ABA

https://en.wikipedia.org/wiki/ABA_problem

---

### Atomic queue

---

### Patterns

- map-reduce
- producer-consumer

---

#### Map Reduce

- split and map work on all threads
- reduce the results from the threads to the final result

---

#### Parallel Merge Sort

---
	template <typename I>
	void parallel_merge_sort(I begin, I end)
	{
		auto count = std::distance(begin, end);
		I m = std::advance(begin, count / 2);

		if (count < MeasuredConstant || !can_not_spawn_more_threads) {
			sort_somehow(begin, m);
			sort_somehow(m, end);
		} else {
			std::thread t(parallel_merge_sort, begin, m);
			parallel_merge_sort(m, end);
			t.join();
		}
		merge(begin, m, end);
	}
---

What is the speed up we get?

- Even with infinite number of processors the merge is linear

---

---
	template <typename I>
	void parallel_merge_sort(I begin, I end)
	{
		auto count = std::distance(begin, end);
		I m = std::advance(begin, count / 2);

		if (count < MeasuredConstant || !can_not_spawn_more_threads) {
			sort_somehow(begin, m);
			sort_somehow(m, end);
		} else {
			std::thread t(parallel_merge_sort, begin, m);
			parallel_merge_sort(m, end);
			t.join();
		}
		parallel_merge(begin, m, end);
	}
---
	template <typename I>
	std::pair<I, I> merge_helper_less(I b1, I e1, I b2, I e2, I o, I oe)
	{
		while (b1 != e1 && b2 != e2 && o != oe) {
			if (*b1 < *b2)
				*o++ = *b1++;
			else
				*o++ = *b2++;
		}
		return std::make_pair(b1, b2);
	}

	template <typename I>
	std::pair<I, I> merge_helper_gt(I b1, I e1, I b2, I e2, I o, I oe)
	{
		while (b1 != e1 && b2 != e2 && o != oe) {
			if (*b1 < *b2)
				*o-- = *b2--
			else
				*o-- = *b1--;
		}
		return std::make_pair(b1, b2);
	}

	template <typename I>
	void parallel_merge(I begin, I m, I end)
	{
		auto count = std::distance(begin, end);
		if (count < MeasuredConstant)
		{
			merge_some_how(begin, m, end);
			return;
		}

		auto count_p = std::min(m - begin, end - m);
		auto buffer = GetTemporaryBuffer(count);
		auto lower_task = std::async(merge_helper_less(b, m, m, e,
					buffer.begin(), buffer.begin() + count_p);
		auto higher = merge_helper_gt(m, b, e, m,
					buffer.end() - 1, buffer.end() - 1 - count_p);
		lower = lower_task.get();
		merge_helper_less(lower.first, higher.first, lower.second,
					higher.second, buffer.begin() + count_p);
	}

---

#### Producer-Consumer

- One thread produces tasks for the next thread

---

### Task based systems

---

Used mostly in game engines, where there are a lot of different things happening
every frame

- load a 3D model, or a texture
- read state from network
- update the gameplay word
	- simulation
	- ai
	- physics
- send data to network
- gather things to render
- record render commands
- replay render commands

---

#### Implementation

- Thread pool
- Fix the threads to cores
- Group task in thread (channels)
	- channel for IO
	- channel for GPU commands
	- channel(s) for world update

---

### Work stealing

If a thread in the pool is free, and there are task waiting for another thread
to be execute them. The free thread can "steal" the task and execute it.

---

#### Cooperative multitasking

Using coroutines as tasks can make the code prettier

---

http://www.gdcvault.com/play/1022186/Parallelizing-the-Naughty-Dog-Engine

---

### Libraries

---

#### C++11

- thread
- mutex
- condition_variable
- packaged_task
- future

---

#### OpenMP

Fork-join parallelism
---

![OpenMP](./images/Fork_join.svg)

---

- requires compiler support

---

#### Intel Theading Building Blocks

- data structures
- algorithms
- memory allocators
- task scheduling

### Parallel Patterns Library

- By Microsoft, the good stuff is Windows Only

### Cilk

- Sort of Extension to C++
 
### Tools

1. Thread sanitizer

Resources
---------

-	http://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/
-	http://15418.courses.cs.cmu.edu/spring2015/
